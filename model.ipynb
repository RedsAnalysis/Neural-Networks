{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST(\n",
    "    root = \"data\",\n",
    "    train = True,\n",
    "    transform = ToTensor(),\n",
    "    download = True\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root = \"data\",\n",
    "    train = False,\n",
    "    transform = ToTensor(),\n",
    "    download = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 28, 28])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "loaders = {\n",
    "\n",
    "    'train' : DataLoader(train_data,\n",
    "                         batch_size= 100,\n",
    "                         shuffle = True,\n",
    "                         num_workers=1),\n",
    "    \n",
    "    'test' : DataLoader(test_data,\n",
    "                         batch_size= 100,\n",
    "                         shuffle = True,\n",
    "                         num_workers=1)\n",
    "\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <torch.utils.data.dataloader.DataLoader at 0x7f0394f62e00>,\n",
       " 'test': <torch.utils.data.dataloader.DataLoader at 0x7f0394f627d0>}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Structure of NN\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1,10, kernel_size = 5)\n",
    "        self.conv2 = nn.Conv2d(10,20, kernel_size = 5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320,50)\n",
    "        self.fc2 = nn.Linear(50,10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)) , 2))\n",
    "        x = x.view(-1,320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training = self.training)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return F.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "model = CNN().to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(loaders['train']):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 20 == 0:\n",
    "            print(f'train Epoch: {epoch} [{batch_idx * len(data)}/{len(loaders[\"train\"].dataset)}] ({100. * batch_idx / len(loaders[\"train\"]):.0f}%)]\\t{loss.item():.6f}')\n",
    "\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in loaders['test']:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += loss_fn(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim = True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(loaders['test'].dataset)\n",
    "    print(f'\\nTest set: Avg loss: {test_loss:.4f}, Accuracy: {correct}/{len(loaders[\"test\"].dataset)} 'f'({100. * correct / len(loaders[\"test\"].dataset):.0f}%)\\n')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_89614/3005187229.py:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Epoch: 1 [0/60000] (0%)]\t2.302269\n",
      "train Epoch: 1 [2000/60000] (3%)]\t2.255672\n",
      "train Epoch: 1 [4000/60000] (7%)]\t2.132679\n",
      "train Epoch: 1 [6000/60000] (10%)]\t1.950798\n",
      "train Epoch: 1 [8000/60000] (13%)]\t1.876157\n",
      "train Epoch: 1 [10000/60000] (17%)]\t1.884224\n",
      "train Epoch: 1 [12000/60000] (20%)]\t1.785224\n",
      "train Epoch: 1 [14000/60000] (23%)]\t1.775683\n",
      "train Epoch: 1 [16000/60000] (27%)]\t1.737000\n",
      "train Epoch: 1 [18000/60000] (30%)]\t1.713992\n",
      "train Epoch: 1 [20000/60000] (33%)]\t1.765125\n",
      "train Epoch: 1 [22000/60000] (37%)]\t1.702411\n",
      "train Epoch: 1 [24000/60000] (40%)]\t1.657537\n",
      "train Epoch: 1 [26000/60000] (43%)]\t1.660797\n",
      "train Epoch: 1 [28000/60000] (47%)]\t1.668110\n",
      "train Epoch: 1 [30000/60000] (50%)]\t1.646352\n",
      "train Epoch: 1 [32000/60000] (53%)]\t1.676582\n",
      "train Epoch: 1 [34000/60000] (57%)]\t1.662540\n",
      "train Epoch: 1 [36000/60000] (60%)]\t1.673964\n",
      "train Epoch: 1 [38000/60000] (63%)]\t1.617643\n",
      "train Epoch: 1 [40000/60000] (67%)]\t1.579308\n",
      "train Epoch: 1 [42000/60000] (70%)]\t1.702323\n",
      "train Epoch: 1 [44000/60000] (73%)]\t1.622855\n",
      "train Epoch: 1 [46000/60000] (77%)]\t1.591467\n",
      "train Epoch: 1 [48000/60000] (80%)]\t1.668536\n",
      "train Epoch: 1 [50000/60000] (83%)]\t1.567298\n",
      "train Epoch: 1 [52000/60000] (87%)]\t1.567941\n",
      "train Epoch: 1 [54000/60000] (90%)]\t1.649803\n",
      "train Epoch: 1 [56000/60000] (93%)]\t1.639085\n",
      "train Epoch: 1 [58000/60000] (97%)]\t1.570089\n",
      "\n",
      "Test set: Avg loss: 0.0153, Accuracy: 9314/10000 (93%)\n",
      "\n",
      "train Epoch: 2 [0/60000] (0%)]\t1.638287\n",
      "train Epoch: 2 [2000/60000] (3%)]\t1.627483\n",
      "train Epoch: 2 [4000/60000] (7%)]\t1.574919\n",
      "train Epoch: 2 [6000/60000] (10%)]\t1.615752\n",
      "train Epoch: 2 [8000/60000] (13%)]\t1.598041\n",
      "train Epoch: 2 [10000/60000] (17%)]\t1.565988\n",
      "train Epoch: 2 [12000/60000] (20%)]\t1.584746\n",
      "train Epoch: 2 [14000/60000] (23%)]\t1.606403\n",
      "train Epoch: 2 [16000/60000] (27%)]\t1.560115\n",
      "train Epoch: 2 [18000/60000] (30%)]\t1.551850\n",
      "train Epoch: 2 [20000/60000] (33%)]\t1.598402\n",
      "train Epoch: 2 [22000/60000] (37%)]\t1.504499\n",
      "train Epoch: 2 [24000/60000] (40%)]\t1.585651\n",
      "train Epoch: 2 [26000/60000] (43%)]\t1.619049\n",
      "train Epoch: 2 [28000/60000] (47%)]\t1.562987\n",
      "train Epoch: 2 [30000/60000] (50%)]\t1.561444\n",
      "train Epoch: 2 [32000/60000] (53%)]\t1.605897\n",
      "train Epoch: 2 [34000/60000] (57%)]\t1.601134\n",
      "train Epoch: 2 [36000/60000] (60%)]\t1.603914\n",
      "train Epoch: 2 [38000/60000] (63%)]\t1.540686\n",
      "train Epoch: 2 [40000/60000] (67%)]\t1.552047\n",
      "train Epoch: 2 [42000/60000] (70%)]\t1.596814\n",
      "train Epoch: 2 [44000/60000] (73%)]\t1.537913\n",
      "train Epoch: 2 [46000/60000] (77%)]\t1.552949\n",
      "train Epoch: 2 [48000/60000] (80%)]\t1.546178\n",
      "train Epoch: 2 [50000/60000] (83%)]\t1.556134\n",
      "train Epoch: 2 [52000/60000] (87%)]\t1.548077\n",
      "train Epoch: 2 [54000/60000] (90%)]\t1.577533\n",
      "train Epoch: 2 [56000/60000] (93%)]\t1.524140\n",
      "train Epoch: 2 [58000/60000] (97%)]\t1.567800\n",
      "\n",
      "Test set: Avg loss: 0.0151, Accuracy: 9555/10000 (96%)\n",
      "\n",
      "train Epoch: 3 [0/60000] (0%)]\t1.620121\n",
      "train Epoch: 3 [2000/60000] (3%)]\t1.533186\n",
      "train Epoch: 3 [4000/60000] (7%)]\t1.587248\n",
      "train Epoch: 3 [6000/60000] (10%)]\t1.559648\n",
      "train Epoch: 3 [8000/60000] (13%)]\t1.561594\n",
      "train Epoch: 3 [10000/60000] (17%)]\t1.596848\n",
      "train Epoch: 3 [12000/60000] (20%)]\t1.595034\n",
      "train Epoch: 3 [14000/60000] (23%)]\t1.590646\n",
      "train Epoch: 3 [16000/60000] (27%)]\t1.538535\n",
      "train Epoch: 3 [18000/60000] (30%)]\t1.557651\n",
      "train Epoch: 3 [20000/60000] (33%)]\t1.532319\n",
      "train Epoch: 3 [22000/60000] (37%)]\t1.541036\n",
      "train Epoch: 3 [24000/60000] (40%)]\t1.584193\n",
      "train Epoch: 3 [26000/60000] (43%)]\t1.510293\n",
      "train Epoch: 3 [28000/60000] (47%)]\t1.562804\n",
      "train Epoch: 3 [30000/60000] (50%)]\t1.599805\n",
      "train Epoch: 3 [32000/60000] (53%)]\t1.544079\n",
      "train Epoch: 3 [34000/60000] (57%)]\t1.548327\n",
      "train Epoch: 3 [36000/60000] (60%)]\t1.592322\n",
      "train Epoch: 3 [38000/60000] (63%)]\t1.545359\n",
      "train Epoch: 3 [40000/60000] (67%)]\t1.572890\n",
      "train Epoch: 3 [42000/60000] (70%)]\t1.580592\n",
      "train Epoch: 3 [44000/60000] (73%)]\t1.553588\n",
      "train Epoch: 3 [46000/60000] (77%)]\t1.534762\n",
      "train Epoch: 3 [48000/60000] (80%)]\t1.553015\n",
      "train Epoch: 3 [50000/60000] (83%)]\t1.573859\n",
      "train Epoch: 3 [52000/60000] (87%)]\t1.509873\n",
      "train Epoch: 3 [54000/60000] (90%)]\t1.587239\n",
      "train Epoch: 3 [56000/60000] (93%)]\t1.564537\n",
      "train Epoch: 3 [58000/60000] (97%)]\t1.537442\n",
      "\n",
      "Test set: Avg loss: 0.0150, Accuracy: 9605/10000 (96%)\n",
      "\n",
      "train Epoch: 4 [0/60000] (0%)]\t1.598519\n",
      "train Epoch: 4 [2000/60000] (3%)]\t1.586207\n",
      "train Epoch: 4 [4000/60000] (7%)]\t1.569842\n",
      "train Epoch: 4 [6000/60000] (10%)]\t1.554986\n",
      "train Epoch: 4 [8000/60000] (13%)]\t1.535067\n",
      "train Epoch: 4 [10000/60000] (17%)]\t1.546238\n",
      "train Epoch: 4 [12000/60000] (20%)]\t1.576590\n",
      "train Epoch: 4 [14000/60000] (23%)]\t1.560090\n",
      "train Epoch: 4 [16000/60000] (27%)]\t1.523753\n",
      "train Epoch: 4 [18000/60000] (30%)]\t1.561927\n",
      "train Epoch: 4 [20000/60000] (33%)]\t1.536029\n",
      "train Epoch: 4 [22000/60000] (37%)]\t1.590001\n",
      "train Epoch: 4 [24000/60000] (40%)]\t1.566144\n",
      "train Epoch: 4 [26000/60000] (43%)]\t1.546732\n",
      "train Epoch: 4 [28000/60000] (47%)]\t1.548312\n",
      "train Epoch: 4 [30000/60000] (50%)]\t1.573528\n",
      "train Epoch: 4 [32000/60000] (53%)]\t1.541596\n",
      "train Epoch: 4 [34000/60000] (57%)]\t1.524645\n",
      "train Epoch: 4 [36000/60000] (60%)]\t1.538319\n",
      "train Epoch: 4 [38000/60000] (63%)]\t1.611153\n",
      "train Epoch: 4 [40000/60000] (67%)]\t1.579057\n",
      "train Epoch: 4 [42000/60000] (70%)]\t1.585680\n",
      "train Epoch: 4 [44000/60000] (73%)]\t1.547050\n",
      "train Epoch: 4 [46000/60000] (77%)]\t1.554199\n",
      "train Epoch: 4 [48000/60000] (80%)]\t1.560897\n",
      "train Epoch: 4 [50000/60000] (83%)]\t1.512162\n",
      "train Epoch: 4 [52000/60000] (87%)]\t1.553119\n",
      "train Epoch: 4 [54000/60000] (90%)]\t1.521453\n",
      "train Epoch: 4 [56000/60000] (93%)]\t1.543579\n",
      "train Epoch: 4 [58000/60000] (97%)]\t1.546786\n",
      "\n",
      "Test set: Avg loss: 0.0150, Accuracy: 9642/10000 (96%)\n",
      "\n",
      "train Epoch: 5 [0/60000] (0%)]\t1.531889\n",
      "train Epoch: 5 [2000/60000] (3%)]\t1.524255\n",
      "train Epoch: 5 [4000/60000] (7%)]\t1.489875\n",
      "train Epoch: 5 [6000/60000] (10%)]\t1.572688\n",
      "train Epoch: 5 [8000/60000] (13%)]\t1.587130\n",
      "train Epoch: 5 [10000/60000] (17%)]\t1.575056\n",
      "train Epoch: 5 [12000/60000] (20%)]\t1.588490\n",
      "train Epoch: 5 [14000/60000] (23%)]\t1.538102\n",
      "train Epoch: 5 [16000/60000] (27%)]\t1.520350\n",
      "train Epoch: 5 [18000/60000] (30%)]\t1.537592\n",
      "train Epoch: 5 [20000/60000] (33%)]\t1.565118\n",
      "train Epoch: 5 [22000/60000] (37%)]\t1.522358\n",
      "train Epoch: 5 [24000/60000] (40%)]\t1.521060\n",
      "train Epoch: 5 [26000/60000] (43%)]\t1.533545\n",
      "train Epoch: 5 [28000/60000] (47%)]\t1.533333\n",
      "train Epoch: 5 [30000/60000] (50%)]\t1.515041\n",
      "train Epoch: 5 [32000/60000] (53%)]\t1.528319\n",
      "train Epoch: 5 [34000/60000] (57%)]\t1.550623\n",
      "train Epoch: 5 [36000/60000] (60%)]\t1.493183\n",
      "train Epoch: 5 [38000/60000] (63%)]\t1.562979\n",
      "train Epoch: 5 [40000/60000] (67%)]\t1.512307\n",
      "train Epoch: 5 [42000/60000] (70%)]\t1.521581\n",
      "train Epoch: 5 [44000/60000] (73%)]\t1.548788\n",
      "train Epoch: 5 [46000/60000] (77%)]\t1.578921\n",
      "train Epoch: 5 [48000/60000] (80%)]\t1.554758\n",
      "train Epoch: 5 [50000/60000] (83%)]\t1.520930\n",
      "train Epoch: 5 [52000/60000] (87%)]\t1.572868\n",
      "train Epoch: 5 [54000/60000] (90%)]\t1.569222\n",
      "train Epoch: 5 [56000/60000] (93%)]\t1.566755\n",
      "train Epoch: 5 [58000/60000] (97%)]\t1.495510\n",
      "\n",
      "Test set: Avg loss: 0.0149, Accuracy: 9666/10000 (97%)\n",
      "\n",
      "train Epoch: 6 [0/60000] (0%)]\t1.535713\n",
      "train Epoch: 6 [2000/60000] (3%)]\t1.541516\n",
      "train Epoch: 6 [4000/60000] (7%)]\t1.574220\n",
      "train Epoch: 6 [6000/60000] (10%)]\t1.551159\n",
      "train Epoch: 6 [8000/60000] (13%)]\t1.571097\n",
      "train Epoch: 6 [10000/60000] (17%)]\t1.535588\n",
      "train Epoch: 6 [12000/60000] (20%)]\t1.492433\n",
      "train Epoch: 6 [14000/60000] (23%)]\t1.531119\n",
      "train Epoch: 6 [16000/60000] (27%)]\t1.566403\n",
      "train Epoch: 6 [18000/60000] (30%)]\t1.531861\n",
      "train Epoch: 6 [20000/60000] (33%)]\t1.564150\n",
      "train Epoch: 6 [22000/60000] (37%)]\t1.567513\n",
      "train Epoch: 6 [24000/60000] (40%)]\t1.543691\n",
      "train Epoch: 6 [26000/60000] (43%)]\t1.564297\n",
      "train Epoch: 6 [28000/60000] (47%)]\t1.541587\n",
      "train Epoch: 6 [30000/60000] (50%)]\t1.581180\n",
      "train Epoch: 6 [32000/60000] (53%)]\t1.535607\n",
      "train Epoch: 6 [34000/60000] (57%)]\t1.522542\n",
      "train Epoch: 6 [36000/60000] (60%)]\t1.529511\n",
      "train Epoch: 6 [38000/60000] (63%)]\t1.516418\n",
      "train Epoch: 6 [40000/60000] (67%)]\t1.545491\n",
      "train Epoch: 6 [42000/60000] (70%)]\t1.552505\n",
      "train Epoch: 6 [44000/60000] (73%)]\t1.531689\n",
      "train Epoch: 6 [46000/60000] (77%)]\t1.531169\n",
      "train Epoch: 6 [48000/60000] (80%)]\t1.510623\n",
      "train Epoch: 6 [50000/60000] (83%)]\t1.521392\n",
      "train Epoch: 6 [52000/60000] (87%)]\t1.516974\n",
      "train Epoch: 6 [54000/60000] (90%)]\t1.539079\n",
      "train Epoch: 6 [56000/60000] (93%)]\t1.497869\n",
      "train Epoch: 6 [58000/60000] (97%)]\t1.577556\n",
      "\n",
      "Test set: Avg loss: 0.0149, Accuracy: 9680/10000 (97%)\n",
      "\n",
      "train Epoch: 7 [0/60000] (0%)]\t1.573163\n",
      "train Epoch: 7 [2000/60000] (3%)]\t1.553813\n",
      "train Epoch: 7 [4000/60000] (7%)]\t1.602475\n",
      "train Epoch: 7 [6000/60000] (10%)]\t1.540031\n",
      "train Epoch: 7 [8000/60000] (13%)]\t1.516716\n",
      "train Epoch: 7 [10000/60000] (17%)]\t1.510100\n",
      "train Epoch: 7 [12000/60000] (20%)]\t1.518668\n",
      "train Epoch: 7 [14000/60000] (23%)]\t1.561194\n",
      "train Epoch: 7 [16000/60000] (27%)]\t1.530212\n",
      "train Epoch: 7 [18000/60000] (30%)]\t1.541599\n",
      "train Epoch: 7 [20000/60000] (33%)]\t1.552183\n",
      "train Epoch: 7 [22000/60000] (37%)]\t1.538269\n",
      "train Epoch: 7 [24000/60000] (40%)]\t1.515147\n",
      "train Epoch: 7 [26000/60000] (43%)]\t1.525825\n",
      "train Epoch: 7 [28000/60000] (47%)]\t1.586193\n",
      "train Epoch: 7 [30000/60000] (50%)]\t1.534047\n",
      "train Epoch: 7 [32000/60000] (53%)]\t1.513956\n",
      "train Epoch: 7 [34000/60000] (57%)]\t1.534613\n",
      "train Epoch: 7 [36000/60000] (60%)]\t1.548396\n",
      "train Epoch: 7 [38000/60000] (63%)]\t1.492236\n",
      "train Epoch: 7 [40000/60000] (67%)]\t1.550260\n",
      "train Epoch: 7 [42000/60000] (70%)]\t1.580618\n",
      "train Epoch: 7 [44000/60000] (73%)]\t1.545946\n",
      "train Epoch: 7 [46000/60000] (77%)]\t1.552187\n",
      "train Epoch: 7 [48000/60000] (80%)]\t1.531261\n",
      "train Epoch: 7 [50000/60000] (83%)]\t1.527308\n",
      "train Epoch: 7 [52000/60000] (87%)]\t1.522797\n",
      "train Epoch: 7 [54000/60000] (90%)]\t1.537652\n",
      "train Epoch: 7 [56000/60000] (93%)]\t1.511892\n",
      "train Epoch: 7 [58000/60000] (97%)]\t1.485874\n",
      "\n",
      "Test set: Avg loss: 0.0149, Accuracy: 9699/10000 (97%)\n",
      "\n",
      "train Epoch: 8 [0/60000] (0%)]\t1.548087\n",
      "train Epoch: 8 [2000/60000] (3%)]\t1.593306\n",
      "train Epoch: 8 [4000/60000] (7%)]\t1.509952\n",
      "train Epoch: 8 [6000/60000] (10%)]\t1.526353\n",
      "train Epoch: 8 [8000/60000] (13%)]\t1.535972\n",
      "train Epoch: 8 [10000/60000] (17%)]\t1.520019\n",
      "train Epoch: 8 [12000/60000] (20%)]\t1.515797\n",
      "train Epoch: 8 [14000/60000] (23%)]\t1.528035\n",
      "train Epoch: 8 [16000/60000] (27%)]\t1.546238\n",
      "train Epoch: 8 [18000/60000] (30%)]\t1.477409\n",
      "train Epoch: 8 [20000/60000] (33%)]\t1.534551\n",
      "train Epoch: 8 [22000/60000] (37%)]\t1.559103\n",
      "train Epoch: 8 [24000/60000] (40%)]\t1.539068\n",
      "train Epoch: 8 [26000/60000] (43%)]\t1.527058\n",
      "train Epoch: 8 [28000/60000] (47%)]\t1.520356\n",
      "train Epoch: 8 [30000/60000] (50%)]\t1.501781\n",
      "train Epoch: 8 [32000/60000] (53%)]\t1.518263\n",
      "train Epoch: 8 [34000/60000] (57%)]\t1.524404\n",
      "train Epoch: 8 [36000/60000] (60%)]\t1.492844\n",
      "train Epoch: 8 [38000/60000] (63%)]\t1.539957\n",
      "train Epoch: 8 [40000/60000] (67%)]\t1.491373\n",
      "train Epoch: 8 [42000/60000] (70%)]\t1.543218\n",
      "train Epoch: 8 [44000/60000] (73%)]\t1.504650\n",
      "train Epoch: 8 [46000/60000] (77%)]\t1.501904\n",
      "train Epoch: 8 [48000/60000] (80%)]\t1.494261\n",
      "train Epoch: 8 [50000/60000] (83%)]\t1.519650\n",
      "train Epoch: 8 [52000/60000] (87%)]\t1.579247\n",
      "train Epoch: 8 [54000/60000] (90%)]\t1.532181\n",
      "train Epoch: 8 [56000/60000] (93%)]\t1.543696\n",
      "train Epoch: 8 [58000/60000] (97%)]\t1.521174\n",
      "\n",
      "Test set: Avg loss: 0.0149, Accuracy: 9730/10000 (97%)\n",
      "\n",
      "train Epoch: 9 [0/60000] (0%)]\t1.588013\n",
      "train Epoch: 9 [2000/60000] (3%)]\t1.546608\n",
      "train Epoch: 9 [4000/60000] (7%)]\t1.501839\n",
      "train Epoch: 9 [6000/60000] (10%)]\t1.521865\n",
      "train Epoch: 9 [8000/60000] (13%)]\t1.528466\n",
      "train Epoch: 9 [10000/60000] (17%)]\t1.507073\n",
      "train Epoch: 9 [12000/60000] (20%)]\t1.560497\n",
      "train Epoch: 9 [14000/60000] (23%)]\t1.539932\n",
      "train Epoch: 9 [16000/60000] (27%)]\t1.523495\n",
      "train Epoch: 9 [18000/60000] (30%)]\t1.521723\n",
      "train Epoch: 9 [20000/60000] (33%)]\t1.515663\n",
      "train Epoch: 9 [22000/60000] (37%)]\t1.534381\n",
      "train Epoch: 9 [24000/60000] (40%)]\t1.543909\n",
      "train Epoch: 9 [26000/60000] (43%)]\t1.556261\n",
      "train Epoch: 9 [28000/60000] (47%)]\t1.514086\n",
      "train Epoch: 9 [30000/60000] (50%)]\t1.540568\n",
      "train Epoch: 9 [32000/60000] (53%)]\t1.530116\n",
      "train Epoch: 9 [34000/60000] (57%)]\t1.524834\n",
      "train Epoch: 9 [36000/60000] (60%)]\t1.530859\n",
      "train Epoch: 9 [38000/60000] (63%)]\t1.494087\n",
      "train Epoch: 9 [40000/60000] (67%)]\t1.528763\n",
      "train Epoch: 9 [42000/60000] (70%)]\t1.565064\n",
      "train Epoch: 9 [44000/60000] (73%)]\t1.530258\n",
      "train Epoch: 9 [46000/60000] (77%)]\t1.506308\n",
      "train Epoch: 9 [48000/60000] (80%)]\t1.512160\n",
      "train Epoch: 9 [50000/60000] (83%)]\t1.499384\n",
      "train Epoch: 9 [52000/60000] (87%)]\t1.526391\n",
      "train Epoch: 9 [54000/60000] (90%)]\t1.528017\n",
      "train Epoch: 9 [56000/60000] (93%)]\t1.492300\n",
      "train Epoch: 9 [58000/60000] (97%)]\t1.514881\n",
      "\n",
      "Test set: Avg loss: 0.0149, Accuracy: 9759/10000 (98%)\n",
      "\n",
      "train Epoch: 10 [0/60000] (0%)]\t1.530571\n",
      "train Epoch: 10 [2000/60000] (3%)]\t1.486159\n",
      "train Epoch: 10 [4000/60000] (7%)]\t1.551399\n",
      "train Epoch: 10 [6000/60000] (10%)]\t1.537300\n",
      "train Epoch: 10 [8000/60000] (13%)]\t1.524573\n",
      "train Epoch: 10 [10000/60000] (17%)]\t1.562867\n",
      "train Epoch: 10 [12000/60000] (20%)]\t1.508815\n",
      "train Epoch: 10 [14000/60000] (23%)]\t1.511962\n",
      "train Epoch: 10 [16000/60000] (27%)]\t1.504739\n",
      "train Epoch: 10 [18000/60000] (30%)]\t1.546887\n",
      "train Epoch: 10 [20000/60000] (33%)]\t1.520084\n",
      "train Epoch: 10 [22000/60000] (37%)]\t1.526210\n",
      "train Epoch: 10 [24000/60000] (40%)]\t1.551299\n",
      "train Epoch: 10 [26000/60000] (43%)]\t1.518181\n",
      "train Epoch: 10 [28000/60000] (47%)]\t1.529794\n",
      "train Epoch: 10 [30000/60000] (50%)]\t1.497848\n",
      "train Epoch: 10 [32000/60000] (53%)]\t1.538622\n",
      "train Epoch: 10 [34000/60000] (57%)]\t1.499662\n",
      "train Epoch: 10 [36000/60000] (60%)]\t1.521289\n",
      "train Epoch: 10 [38000/60000] (63%)]\t1.524669\n",
      "train Epoch: 10 [40000/60000] (67%)]\t1.516464\n",
      "train Epoch: 10 [42000/60000] (70%)]\t1.494656\n",
      "train Epoch: 10 [44000/60000] (73%)]\t1.505900\n",
      "train Epoch: 10 [46000/60000] (77%)]\t1.507547\n",
      "train Epoch: 10 [48000/60000] (80%)]\t1.534103\n",
      "train Epoch: 10 [50000/60000] (83%)]\t1.539118\n",
      "train Epoch: 10 [52000/60000] (87%)]\t1.553504\n",
      "train Epoch: 10 [54000/60000] (90%)]\t1.519599\n",
      "train Epoch: 10 [56000/60000] (93%)]\t1.530199\n",
      "train Epoch: 10 [58000/60000] (97%)]\t1.539984\n",
      "\n",
      "Test set: Avg loss: 0.0149, Accuracy: 9736/10000 (97%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1,11):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Save the model\n",
    "model_path = '/mnt/d/projects/MNISTdigits/models/mnist_cnn_model.pth'\n",
    "torch.save(model.state_dict(), model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_100673/3005187229.py:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(x)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGzCAYAAABpdMNsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/TGe4hAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAnGElEQVR4nO3df1xVdZ7H8fdF4YIKKMjPVETMavzVpklaoiWBP0utXXXcGWzasgYts7SlH6LmPJip3damUdsfk1T+yHyUujWNrqJgNWqj6cPVSR/CUupD0HTjopC/4Lt/uNzpCogX7/UL+Ho+Ht/Hg3vO+Zzz4XS6b8+5h3MdxhgjAACuswDbDQAAbkwEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEJqUrl27asqUKe7X+fn5cjgcys/Pt9bT5S7vEddmypQp6tq1q+02YAEBBLfc3Fw5HA73CA4OVo8ePTRt2jQdP37cdnte+fTTTzV37lzbbdRy4MABzZ49W7fffrtCQ0MVFxenUaNGaefOnT5Zf1lZmYKDg+VwOPT11183ej2LFy9Wbm6uT3ryp1OnTum1115TSkqKoqKi1L59e911111atWqV7dZwFQgg1DJ//ny99957+t3vfqdBgwZpyZIlGjhwoCorK697LykpKfrhhx+UkpLiVd2nn36qefPm+amrxvuP//gP/fu//7v69++vf/7nf9bMmTN18OBB3XXXXdq0adM1r3/16tVyOByKjY3V8uXLG72e5hJA27Zt04svvqiIiAi99NJL+tWvfqU2bdpo4sSJys7Ott0eGtDadgNoekaMGKH+/ftLkv7hH/5BkZGRev3117Vu3TpNmjSpzpqKigq1bdvW570EBAQoODjY5+u1ZdKkSZo7d67atWvnnvaLX/xCt912m+bOnavU1NRrWv+yZcs0cuRIJSQkaMWKFVqwYMG1ttyk9ezZU4cOHVJCQoJ72i9/+UulpqbqN7/5jWbPnu2X4xK+wRkQGnTfffdJkoqLiyVdumbfrl07FRUVaeTIkQoNDdXkyZMlSdXV1Vq4cKF69uyp4OBgxcTEaOrUqfr+++891mmM0YIFC9SpUye1adNG9957r/bv319r2/V9BrRjxw6NHDlSHTp0UNu2bdWnTx+98cYb7v4WLVokSR6XFGv4ukdJKioqUlFRUYP7sl+/fh7hI0mRkZEaPHjwNV0yk6TDhw/rs88+08SJEzVx4kQVFxfrT3/6U53LLlu2TAMGDFCbNm3UoUMHpaSk6L/+678kXfqMa//+/SooKHDvu6FDh0qS5s6d67Eva9Rcvv3mm2/c09atW6dRo0YpPj5eTqdTSUlJeuWVV1RVVdXg71JSUqIDBw7owoULV1wuMTHRI3ykS//Nx44dq3Pnzul//ud/GtwW7OEMCA2qeWONjIx0T7t48aLS09N1zz336J/+6Z/Upk0bSdLUqVOVm5urRx55RE899ZSKi4v1u9/9Trt379YXX3yhwMBASdKcOXO0YMECjRw5UiNHjtRXX32ltLQ0nT9/vsF+Nm7cqNGjRysuLk5PP/20YmNj9fXXX+uTTz7R008/ralTp+rYsWPauHGj3nvvvVr1/uhx2LBhkuTxBuyN0tJSdezYsVG1NVauXKm2bdtq9OjRCgkJUVJSkpYvX65BgwZ5LDdv3jzNnTtXgwYN0vz58xUUFKQdO3Zo8+bNSktL08KFCzV9+nS1a9dOL774oiQpJibG635yc3PVrl07zZw5U+3atdPmzZs1Z84clZeX67XXXrtibVZWlt555x0VFxc36gaF0tJSSbrmfQo/M8D/W7p0qZFkNm3aZL777jtz5MgR8/7775vIyEgTEhJijh49aowxJiMjw0gy//iP/+hR/9lnnxlJZvny5R7T169f7zH9xIkTJigoyIwaNcpUV1e7l3vhhReMJJORkeGetmXLFiPJbNmyxRhjzMWLF01iYqJJSEgw33//vcd2fryuzMxMU9fh7Y8ejTEmISHBJCQk1Nre1di6datxOBzm5ZdfblR9jd69e5vJkye7X7/wwgumY8eO5sKFC+5phw4dMgEBAWbcuHGmqqrKo/7Hv2fPnj3NkCFDam0jOzu7zv1ac+wUFxe7p1VWVtZaburUqaZNmzbm7Nmz7mkZGRm19l3NMfbj9V2tU6dOmejoaDN48GCva3F9cQkOtaSmpioqKkqdO3fWxIkT1a5dO61Zs0Y33XSTx3JPPvmkx+vVq1crPDxc999/v06ePOkeNZedtmzZIknatGmTzp8/r+nTp3tczpkxY0aDve3evVvFxcWaMWOG2rdv7zGvrktDl/NXj998802jzn5OnDihn/70p0pMTNTs2bO9rq+xd+9e/fd//7fHZ3STJk3SyZMntWHDBve0tWvXqrq6WnPmzFFAgOf//lez/7wREhLi/vn06dM6efKkBg8erMrKSh04cOCKtbm5uTLGeH32U11drcmTJ6usrExvvvlmY9rGdcQlONSyaNEi9ejRQ61bt1ZMTIxuueWWWm9WrVu3VqdOnTymHTp0SC6XS9HR0XWu98SJE5Kkb7/9VpJ08803e8yPiopShw4drthbzeXAXr16Xf0vdJ17vFoVFRUaPXq0Tp8+rc8//7zWZ0PeWLZsmdq2batu3bqpsLBQkhQcHKyuXbtq+fLlGjVqlKRL+y8gIEA/+clPfPI7XMn+/fv10ksvafPmzSovL/eY53K5/LLN6dOna/369Xr33XfVt29fv2wDvkMAoZYBAwa474Krj9PprBVK1dXVio6Orvf236ioKJ/12FhNpcfz589r/Pjx2rt3rzZs2NDoQJUu3SyxcuVKVVRU1BksJ06c0JkzZ64p4GrUd5Z0+Y0FZWVlGjJkiMLCwjR//nwlJSUpODhYX331lZ5//nlVV1dfcy+XmzdvnhYvXqxf//rX+tnPfubz9cP3CCD4TFJSkjZt2qS7777b4/LL5WruWjp06JC6devmnv7dd9/VuhOtrm1I0r59+654y3J9b5TXo8eGVFdX6+c//7ny8vL0wQcfaMiQIde0voKCAh09elTz58/Xbbfd5jHv+++/1+OPP661a9fq7//+75WUlKTq6mr95S9/0e23317vOuvbfzVnf2VlZR6XQGvOGGvk5+fr1KlT+uijjzz+hqvmTkpfW7RokebOnasZM2bo+eef98s24Ht8BgSf+bu/+ztVVVXplVdeqTXv4sWLKisrk3TpM6bAwEC9+eabMsa4l1m4cGGD27jjjjuUmJiohQsXutdX48frqvnbj8uX8VePV3sbtnTpMtGqVau0ePFijR8//qpqrqTm8tusWbP08MMPe4zHHntMN998s/uMb+zYsQoICND8+fNrnYVcvv8u33fSX/8BsHXrVve0iooKvfPOOx7LtWrVqtY6z58/r8WLF1/V73S1t2FL0qpVq/TUU09p8uTJev31169q/WgaOAOCzwwZMkRTp05VTk6O9uzZo7S0NAUGBurQoUNavXq13njjDT388MOKiorSc889p5ycHI0ePVojR47U7t279cc//rHB22YDAgK0ZMkSjRkzRrfffrseeeQRxcXF6cCBA9q/f7/7A/d+/fpJkp566imlp6erVatWmjhxot96vNrbsBcuXKjFixdr4MCBatOmjZYtW+Yxf9y4ce7wzM/P17333qvs7Ox6Hyt07tw5ffjhh7r//vvr/YPdBx54QG+88YZOnDih7t2768UXX9Qrr7yiwYMHa/z48XI6nfrzn/+s+Ph45eTkuPffkiVLtGDBAnXv3l3R0dG67777lJaWpi5duujRRx/VrFmz1KpVK7399tuKiorS4cOH3dscNGiQOnTooIyMDD311FNyOBx67733PALpSq72Nuwvv/xSP//5zxUZGalhw4bVurQ6aNAgjzNYNDH2bsBDU1NzK+2f//znKy6XkZFh2rZtW+/8f/u3fzP9+vUzISEhJjQ01PTu3dvMnj3bHDt2zL1MVVWVmTdvnomLizMhISFm6NChZt++fSYhIeGKt2HX+Pzzz839999vQkNDTdu2bU2fPn3Mm2++6Z5/8eJFM336dBMVFWUcDketW4d92aMxV38bds3txfWNH992/PHHHxtJ5q233qp3fR9++KGRZH7/+9/Xu0x+fr6RZN544w33tLffftv8zd/8jXE6naZDhw5myJAhZuPGje75paWlZtSoUSY0NNRI8rgle9euXSY5OdkEBQWZLl26mNdff73O27C/+OILc9ddd5mQkBATHx9vZs+ebTZs2FDrv+e13IZds936xtKlS69YD7scxlzlP0kAXFezZ8/WypUrVVhYKKfTabsdwOf4DAhoorZs2aKXX36Z8EGLxRkQAMAKzoAAAFYQQAAAKwggAIAVBBAAwIom94eo1dXVOnbsmEJDQ33+dF4AgP8ZY3T69GnFx8fXembkjzW5ADp27Jg6d+5suw0AwDU6cuRIrafm/1iTuwQXGhpquwUAgA809H7utwBatGiRunbtquDgYCUnJ+vLL7+8qjouuwFAy9DQ+7lfAmjVqlWaOXOmsrOz9dVXX6lv375KT093f9kXAAB+eRjpgAEDTGZmpvt1VVWViY+PNzk5OQ3WulyuKz5ckMFgMBjNY7hcriu+3/v8DOj8+fPatWuXx5eFBQQEKDU1Vdu2bau1/Llz51ReXu4xAAAtn88D6OTJk6qqqlJMTIzH9JiYGJWWltZaPicnR+Hh4e7BHXAAcGOwfhdcVlaWXC6Xexw5csR2SwCA68DnfwfUsWNHtWrVSsePH/eYfvz4ccXGxtZa3ul08rh5ALgB+fwMKCgoSP369VNeXp57WnV1tfLy8jRw4EBfbw4A0Ez55UkIM2fOVEZGhvr3768BAwZo4cKFqqio0COPPOKPzQEAmiG/BNCECRP03Xffac6cOSotLdXtt9+u9evX17oxAQBw42py34haXl6u8PBw220AAK6Ry+VSWFhYvfOt3wUHALgxEUAAACsIIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACta224AaMhzzz3ndU1ISEijttWnTx+vax5++OFGbctbS5Ys8bpm27ZtjdrWe++916g6wBucAQEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACsIIACAFQ5jjLHdxI+Vl5crPDzcdhvwk1WrVnldc70e9tkSFRUVNaouNTXV65rDhw83altouVwul8LCwuqdzxkQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwggACAFjR2nYDaL5a4oNFDxw44HXNhg0bvK7p1q2b1zVjxozxuiYpKcnrGkmaPHmy1zU5OTmN2hZuXJwBAQCsIIAAAFb4PIDmzp0rh8PhMW699VZfbwYA0Mz55TOgnj17atOmTX/dSGs+agIAePJLMrRu3VqxsbH+WDUAoIXwy2dAhw4dUnx8vLp166bJkydf8at6z507p/Lyco8BAGj5fB5AycnJys3N1fr167VkyRIVFxdr8ODBOn36dJ3L5+TkKDw83D06d+7s65YAAE2QzwNoxIgR+tu//Vv16dNH6enp+vTTT1VWVqYPPvigzuWzsrLkcrnc48iRI75uCQDQBPn97oD27durR48eKiwsrHO+0+mU0+n0dxsAgCbG738HdObMGRUVFSkuLs7fmwIANCM+D6DnnntOBQUF+uabb/SnP/1J48aNU6tWrTRp0iRfbwoA0Iz5/BLc0aNHNWnSJJ06dUpRUVG65557tH37dkVFRfl6UwCAZsznAfT+++/7epXws/79+zeqbty4cT7upG779+/3uuaBBx5o1LZOnjzpdc2ZM2e8rgkKCvK6Zvv27V7X9O3b1+saSYqMjGxUHeANngUHALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAVBBAAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAAFb4/Qvp0PQ19ruaHA6H1zWNebBoenq61zUlJSVe11xPzz77rNc1P/nJT/zQSd3+8Ic/XLdt4cbFGRAAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAVBBAAwAoCCABgBQEEALCCAAIAWEEAAQCs4GnY0Mcff9youu7du3tdc/r0aa9r/vd//9frmqZu4sSJXtcEBgb6oRPAHs6AAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAKHkaKRvv2229tt9AkzJo1y+uaHj16+KGT2nbs2HFd6wBvcAYEALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAVBBAAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAAFbwMFLgR0aPHu11zfz5872uCQoK8rrmxIkTXtdkZWV5XSNJlZWVjaoDvMEZEADACgIIAGCF1wG0detWjRkzRvHx8XI4HFq7dq3HfGOM5syZo7i4OIWEhCg1NVWHDh3yVb8AgBbC6wCqqKhQ3759tWjRojrnv/rqq/rtb3+rt956Szt27FDbtm2Vnp6us2fPXnOzAICWw+ubEEaMGKERI0bUOc8Yo4ULF+qll17Sgw8+KEl69913FRMTo7Vr12rixInX1i0AoMXw6WdAxcXFKi0tVWpqqntaeHi4kpOTtW3btjprzp07p/Lyco8BAGj5fBpApaWlkqSYmBiP6TExMe55l8vJyVF4eLh7dO7c2ZctAQCaKOt3wWVlZcnlcrnHkSNHbLcEALgOfBpAsbGxkqTjx497TD9+/Lh73uWcTqfCwsI8BgCg5fNpACUmJio2NlZ5eXnuaeXl5dqxY4cGDhzoy00BAJo5r++CO3PmjAoLC92vi4uLtWfPHkVERKhLly6aMWOGFixYoJtvvlmJiYl6+eWXFR8fr7Fjx/qybwBAM+d1AO3cuVP33nuv+/XMmTMlSRkZGcrNzdXs2bNVUVGhxx9/XGVlZbrnnnu0fv16BQcH+65rAECz53UADR06VMaYeuc7HA7Nnz+/UQ9oBGzr37+/1zWNebBoY6xatcrrmoKCAj90AviG9bvgAAA3JgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKzw+mnYQHOwdu3aRtWlpaX5tpF6vPvuu17XvPTSS37oBLCHMyAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIKHkaLJi4uL87pm0KBBjdqW0+n0uubkyZNe1yxYsMDrmjNnznhdAzRlnAEBAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBU8jBRN3ocffuh1TWRkpB86qduyZcu8rikqKvJDJ0DzwhkQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwggACAFjBw0hxXT3wwANe19xxxx1+6KRu+fn5XtdkZ2f7vhHgBsAZEADACgIIAGCF1wG0detWjRkzRvHx8XI4HFq7dq3H/ClTpsjhcHiM4cOH+6pfAEAL4XUAVVRUqG/fvlq0aFG9ywwfPlwlJSXusXLlymtqEgDQ8nh9E8KIESM0YsSIKy7jdDoVGxvb6KYAAC2fXz4Dys/PV3R0tG655RY9+eSTOnXqVL3Lnjt3TuXl5R4DANDy+TyAhg8frnfffVd5eXn6zW9+o4KCAo0YMUJVVVV1Lp+Tk6Pw8HD36Ny5s69bAgA0QT7/O6CJEye6f+7du7f69OmjpKQk5efna9iwYbWWz8rK0syZM92vy8vLCSEAuAH4/Tbsbt26qWPHjiosLKxzvtPpVFhYmMcAALR8fg+go0eP6tSpU4qLi/P3pgAAzYjXl+DOnDnjcTZTXFysPXv2KCIiQhEREZo3b54eeughxcbGqqioSLNnz1b37t2Vnp7u08YBAM2b1wG0c+dO3Xvvve7XNZ/fZGRkaMmSJdq7d6/eeecdlZWVKT4+XmlpaXrllVfkdDp91zUAoNnzOoCGDh0qY0y98zds2HBNDaH5iIyM9LrmhRde8LomMDDQ65rG2rNnj9c1Z86c8X0jwA2AZ8EBAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACp9/JTduHM8++6zXNXfeeacfOqlt7dq1jarLzs72bSMA6sUZEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBY4TDGGNtN/Fh5ebnCw8Ntt4GrcPbsWa9rAgMD/dBJbZ06dWpUXUlJiY87AW5cLpdLYWFh9c7nDAgAYAUBBACwggACAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArGhtuwHAHyIiIhpVd+HCBR93YpfL5WpUXWP2Q2MeNHu9Hjzcvn37RtXNnDnTt434UFVVVaPqnn/+ea9rKisrG7WthnAGBACwggACAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABW8DBStEh79+613UKTsHr16kbVlZSUeF0TExPjdc2ECRO8rsG1KS0t9brmV7/6lR864QwIAGAJAQQAsMKrAMrJydGdd96p0NBQRUdHa+zYsTp48KDHMmfPnlVmZqYiIyPVrl07PfTQQzp+/LhPmwYANH9eBVBBQYEyMzO1fft2bdy4URcuXFBaWpoqKircyzzzzDP6+OOPtXr1ahUUFOjYsWMaP368zxsHADRvXt2EsH79eo/Xubm5io6O1q5du5SSkiKXy6Xf//73WrFihe677z5J0tKlS3Xbbbdp+/btuuuuu3zXOQCgWbumz4Bqvu635uuPd+3apQsXLig1NdW9zK233qouXbpo27Ztda7j3LlzKi8v9xgAgJav0QFUXV2tGTNm6O6771avXr0kXbq9LygoqNb3r8fExNR7619OTo7Cw8Pdo3Pnzo1tCQDQjDQ6gDIzM7Vv3z69//7719RAVlaWXC6Xexw5cuSa1gcAaB4a9Yeo06ZN0yeffKKtW7eqU6dO7umxsbE6f/68ysrKPM6Cjh8/rtjY2DrX5XQ65XQ6G9MGAKAZ8+oMyBijadOmac2aNdq8ebMSExM95vfr10+BgYHKy8tzTzt48KAOHz6sgQMH+qZjAECL4NUZUGZmplasWKF169YpNDTU/blOeHi4QkJCFB4erkcffVQzZ85URESEwsLCNH36dA0cOJA74AAAHrwKoCVLlkiShg4d6jF96dKlmjJliiTpX/7lXxQQEKCHHnpI586dU3p6uhYvXuyTZgEALYfDGGNsN/Fj5eXlCg8Pt90GrsJHH33kdc2DDz7oh05wI7l48aLXNdXV1X7opG7/+Z//6XXNzp07/dBJ3T777DOva7Zv396obblcLoWFhdU7n2fBAQCsIIAAAFYQQAAAKwggAIAVBBAAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAVBBAAwAqeho3ravbs2V7XBAYG+qET3+nZs6fXNRMmTPBDJ77z9ttve13zzTff+L6ROnz44Yde1xw4cMAPnaAhPA0bANAkEUAAACsIIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAKHkYKAPALHkYKAGiSCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGCFVwGUk5OjO++8U6GhoYqOjtbYsWN18OBBj2WGDh0qh8PhMZ544gmfNg0AaP68CqCCggJlZmZq+/bt2rhxoy5cuKC0tDRVVFR4LPfYY4+ppKTEPV599VWfNg0AaP5ae7Pw+vXrPV7n5uYqOjpau3btUkpKint6mzZtFBsb65sOAQAt0jV9BuRyuSRJERERHtOXL1+ujh07qlevXsrKylJlZWW96zh37pzKy8s9BgDgBmAaqaqqyowaNcrcfffdHtP/9V//1axfv97s3bvXLFu2zNx0001m3Lhx9a4nOzvbSGIwGAxGCxsul+uKOdLoAHriiSdMQkKCOXLkyBWXy8vLM5JMYWFhnfPPnj1rXC6Xexw5csT6TmMwGAzGtY+GAsirz4BqTJs2TZ988om2bt2qTp06XXHZ5ORkSVJhYaGSkpJqzXc6nXI6nY1pAwDQjHkVQMYYTZ8+XWvWrFF+fr4SExMbrNmzZ48kKS4urlENAgBaJq8CKDMzUytWrNC6desUGhqq0tJSSVJ4eLhCQkJUVFSkFStWaOTIkYqMjNTevXv1zDPPKCUlRX369PHLLwAAaKa8+dxH9VznW7p0qTHGmMOHD5uUlBQTERFhnE6n6d69u5k1a1aD1wF/zOVyWb9uyWAwGIxrHw299zv+P1iajPLycoWHh9tuAwBwjVwul8LCwuqdz7PgAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWNLkAMsbYbgEA4AMNvZ83uQA6ffq07RYAAD7Q0Pu5wzSxU47q6modO3ZMoaGhcjgcHvPKy8vVuXNnHTlyRGFhYZY6tI/9cAn74RL2wyXsh0uawn4wxuj06dOKj49XQED95zmtr2NPVyUgIECdOnW64jJhYWE39AFWg/1wCfvhEvbDJeyHS2zvh/Dw8AaXaXKX4AAANwYCCABgRbMKIKfTqezsbDmdTtutWMV+uIT9cAn74RL2wyXNaT80uZsQAAA3hmZ1BgQAaDkIIACAFQQQAMAKAggAYAUBBACwotkE0KJFi9S1a1cFBwcrOTlZX375pe2Wrru5c+fK4XB4jFtvvdV2W363detWjRkzRvHx8XI4HFq7dq3HfGOM5syZo7i4OIWEhCg1NVWHDh2y06wfNbQfpkyZUuv4GD58uJ1m/SQnJ0d33nmnQkNDFR0drbFjx+rgwYMey5w9e1aZmZmKjIxUu3bt9NBDD+n48eOWOvaPq9kPQ4cOrXU8PPHEE5Y6rluzCKBVq1Zp5syZys7O1ldffaW+ffsqPT1dJ06csN3addezZ0+VlJS4x+eff267Jb+rqKhQ3759tWjRojrnv/rqq/rtb3+rt956Szt27FDbtm2Vnp6us2fPXudO/auh/SBJw4cP9zg+Vq5ceR079L+CggJlZmZq+/bt2rhxoy5cuKC0tDRVVFS4l3nmmWf08ccfa/Xq1SooKNCxY8c0fvx4i1373tXsB0l67LHHPI6HV1991VLH9TDNwIABA0xmZqb7dVVVlYmPjzc5OTkWu7r+srOzTd++fW23YZUks2bNGvfr6upqExsba1577TX3tLKyMuN0Os3KlSstdHh9XL4fjDEmIyPDPPjgg1b6seXEiRNGkikoKDDGXPpvHxgYaFavXu1e5uuvvzaSzLZt22y16XeX7wdjjBkyZIh5+umn7TV1FZr8GdD58+e1a9cupaamuqcFBAQoNTVV27Zts9iZHYcOHVJ8fLy6deumyZMn6/Dhw7Zbsqq4uFilpaUex0d4eLiSk5NvyOMjPz9f0dHRuuWWW/Tkk0/q1KlTtlvyK5fLJUmKiIiQJO3atUsXLlzwOB5uvfVWdenSpUUfD5fvhxrLly9Xx44d1atXL2VlZamystJGe/Vqck/DvtzJkydVVVWlmJgYj+kxMTE6cOCApa7sSE5OVm5urm655RaVlJRo3rx5Gjx4sPbt26fQ0FDb7VlRWloqSXUeHzXzbhTDhw/X+PHjlZiYqKKiIr3wwgsaMWKEtm3bplatWtluz+eqq6s1Y8YM3X333erVq5ekS8dDUFCQ2rdv77FsSz4e6toPkvTTn/5UCQkJio+P1969e/X888/r4MGD+uijjyx266nJBxD+asSIEe6f+/Tpo+TkZCUkJOiDDz7Qo48+arEzNAUTJ050/9y7d2/16dNHSUlJys/P17Bhwyx25h+ZmZnat2/fDfE56JXUtx8ef/xx98+9e/dWXFychg0bpqKiIiUlJV3vNuvU5C/BdezYUa1atap1F8vx48cVGxtrqaumoX379urRo4cKCwttt2JNzTHA8VFbt27d1LFjxxZ5fEybNk2ffPKJtmzZ4vH9YbGxsTp//rzKyso8lm+px0N9+6EuycnJktSkjocmH0BBQUHq16+f8vLy3NOqq6uVl5engQMHWuzMvjNnzqioqEhxcXG2W7EmMTFRsbGxHsdHeXm5duzYccMfH0ePHtWpU6da1PFhjNG0adO0Zs0abd68WYmJiR7z+/Xrp8DAQI/j4eDBgzp8+HCLOh4a2g912bNnjyQ1rePB9l0QV+P99983TqfT5Obmmr/85S/m8ccfN+3btzelpaW2W7uunn32WZOfn2+Ki4vNF198YVJTU03Hjh3NiRMnbLfmV6dPnza7d+82u3fvNpLM66+/bnbv3m2+/fZbY4wxv/71r0379u3NunXrzN69e82DDz5oEhMTzQ8//GC5c9+60n44ffq0ee6558y2bdtMcXGx2bRpk7njjjvMzTffbM6ePWu7dZ958sknTXh4uMnPzzclJSXuUVlZ6V7miSeeMF26dDGbN282O3fuNAMHDjQDBw602LXvNbQfCgsLzfz5883OnTtNcXGxWbdunenWrZtJSUmx3LmnZhFAxhjz5ptvmi5dupigoCAzYMAAs337dtstXXcTJkwwcXFxJigoyNx0001mwoQJprCw0HZbfrdlyxYjqdbIyMgwxly6Ffvll182MTExxul0mmHDhpmDBw/abdoPrrQfKisrTVpamomKijKBgYEmISHBPPbYYy3uH2l1/f6SzNKlS93L/PDDD+aXv/yl6dChg2nTpo0ZN26cKSkpsde0HzS0Hw4fPmxSUlJMRESEcTqdpnv37mbWrFnG5XLZbfwyfB8QAMCKJv8ZEACgZSKAAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACv+D4ZR6mwSJR1nAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the model\n",
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "model = CNN().to(device)\n",
    "\n",
    "model_path = '/mnt/d/projects/MNISTdigits/models/mnist_cnn_model.pth'\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()\n",
    "\n",
    "# Function to test a single image by index\n",
    "def test_single_image(index):\n",
    "    image, label = test_data[index]\n",
    "    image = image.unsqueeze(0).to(device)  # Add batch dimension and move to device\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "        pred_label = output.argmax(dim=1, keepdim=True).item()\n",
    "    \n",
    "    # Display the image\n",
    "    plt.imshow(image.cpu().squeeze(), cmap='gray')\n",
    "    plt.title(f'Predicted: {pred_label}, Actual: {label}')\n",
    "    plt.show()\n",
    "\n",
    "# Test the function with an example index\n",
    "test_single_image(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
